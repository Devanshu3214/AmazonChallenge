{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pip install paddlepaddle-gpu paddleocr"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install pandas requests pillow"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Initialize PaddleOCR model with GPU\n","from paddleocr import PaddleOCR\n","ocr = PaddleOCR(use_angle_cls=True, lang='en', use_gpu=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"trusted":true},"outputs":[],"source":["import pandas as pd\n","import requests\n","import os\n","from paddleocr import PaddleOCR\n","import concurrent.futures\n","from requests.adapters import HTTPAdapter\n","from requests.packages.urllib3.util.retry import Retry\n","\n","# Initialize PaddleOCR with GPU support\n","ocr = PaddleOCR(use_angle_cls=True, lang='en', use_gpu=True)\n","\n","session = requests.Session()\n","retry = Retry(total=5, backoff_factor=0.5, status_forcelist=[429, 500, 502, 503, 504])\n","adapter = HTTPAdapter(max_retries=retry)\n","session.mount('https://', adapter)\n","\n","def download_image(url, save_path):\n","    try:\n","        response = session.get(url, timeout=10)\n","        response.raise_for_status()  \n","        with open(save_path, 'wb') as file:\n","            file.write(response.content)\n","        return save_path\n","    except Exception as e:\n","        print(f\"Failed to download {url}: {e}\")\n","        return None\n","\n","\n","def extract_text_from_image(image_path):\n","    try:\n","        result = ocr.ocr(image_path, cls=True)\n","        extracted_text = ' '.join([line[1][0] for line in result[0]])\n","        return extracted_text\n","    except Exception as e:\n","        print(f\"Failed to extract text from {image_path}: {e}\")\n","        return \"\"\n","\n","def process_row(index, row):\n","    image_url = row['image_link']\n","    image_name = f\"images/image_{index}.jpg\"\n","    \n","    # Download the image\n","    downloaded_image_path = download_image(image_url, image_name)\n","    \n","    if downloaded_image_path:\n","        # Extract text using OCR\n","        extracted_text = extract_text_from_image(downloaded_image_path)\n","        \n","        # Delete the image after processing\n","        os.remove(downloaded_image_path)\n","        \n","        return (index, extracted_text)\n","    return (index, \"\")\n","\n","csv_file = '/kaggle/input/amazon-test/test.csv'  \n","\n","df = pd.read_csv(csv_file)\n","\n","start_index = 30001\n","\n","df_subset = df.iloc[start_index:].copy()\n","\n","df_subset['extracted_text'] = ''\n","\n","os.makedirs('images', exist_ok=True)\n","\n","MAX_THREADS = 8  \n","\n","processed_rows = 0\n","\n","with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n","    # Submit tasks for each row in the subset dataframe\n","    futures = {executor.submit(process_row, index, row): index for index, row in df_subset.iterrows()}\n","    \n","    # As futures complete, update the dataframe with extracted text\n","    for future in concurrent.futures.as_completed(futures):\n","        index, extracted_text = future.result()\n","        df_subset.at[index, 'extracted_text'] = extracted_text\n","        processed_rows += 1\n","        \n","        # Save the DataFrame to a CSV file every 10,000 rows\n","        if processed_rows % 10000 == 0:\n","            updated_file_name = f'updated_file_{start_index + processed_rows}.csv'\n","            df_subset.to_csv(updated_file_name, index=False)\n","            print(f\"Saved progress after {processed_rows} rows\")\n","\n","\n","final_file_name = 'updated_file_Final.csv'\n","df_subset.to_csv(final_file_name, index=False)\n","print(f\"Text extraction, image deletion, and CSV update complete! Final file saved as {final_file_name}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5695719,"sourceId":9387125,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
